{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d1398a-7c8b-4c08-b2f4-530e9086ccfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy (EN): 1.896\n",
      "Entropy (FA): 1.926\n",
      "Entropy (IT): 1.971\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your merged DataFrame, e.g., for GPT-4o\n",
    "df = pd.read_csv(\"GPT4o_Merged_Multilingual.csv\")\n",
    "\n",
    "def compute_entropy(series):\n",
    "    counts = series.value_counts(normalize=True)\n",
    "    entropy = -np.sum(counts * np.log2(counts))\n",
    "    return entropy\n",
    "\n",
    "# Entropy for Persian (FA), Italian (IT), and English (EN)\n",
    "entropy_fa = compute_entropy(df[\"GPT4o_FA\"])\n",
    "entropy_it = compute_entropy(df[\"GPT4o_IT\"])\n",
    "entropy_en = compute_entropy(df[\"GPT4o_EN\"])\n",
    "\n",
    "print(f\"Entropy (EN): {entropy_en:.3f}\")\n",
    "print(f\"Entropy (FA): {entropy_fa:.3f}\")\n",
    "print(f\"Entropy (IT): {entropy_it:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61642349-c80c-4aa5-842c-30b0b54da00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy (EN): 1.988\n",
      "Entropy (FA): 1.972\n",
      "Entropy (IT): 1.879\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your merged DataFrame, e.g., for GPT-4o\n",
    "df = pd.read_csv(\"LLaMA3.1_70_Merged_Multilingual.csv\")\n",
    "\n",
    "def compute_entropy(series):\n",
    "    counts = series.value_counts(normalize=True)\n",
    "    entropy = -np.sum(counts * np.log2(counts))\n",
    "    return entropy\n",
    "\n",
    "# Entropy for Persian (FA), Italian (IT), and English (EN)\n",
    "entropy_fa = compute_entropy(df[\"LLaMA3.1_FA\"])\n",
    "entropy_it = compute_entropy(df[\"LLaMA3.1_IT\"])\n",
    "entropy_en = compute_entropy(df[\"LLaMA3.1_EN\"])\n",
    "\n",
    "print(f\"Entropy (EN): {entropy_en:.3f}\")\n",
    "print(f\"Entropy (FA): {entropy_fa:.3f}\")\n",
    "print(f\"Entropy (IT): {entropy_it:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c079191-b1ef-43f8-b8c8-32c3bd2de203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy (EN): 1.840\n",
      "Entropy (FA): 1.809\n",
      "Entropy (IT): 1.904\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your merged DataFrame, e.g., for GPT-4o\n",
    "df = pd.read_csv(\"LLaMA3.2_Merged_Multilingual.csv\")\n",
    "\n",
    "def compute_entropy(series):\n",
    "    counts = series.value_counts(normalize=True)\n",
    "    entropy = -np.sum(counts * np.log2(counts))\n",
    "    return entropy\n",
    "\n",
    "# Entropy for Persian (FA), Italian (IT), and English (EN)\n",
    "entropy_fa = compute_entropy(df[\"LLaMA_FA\"])\n",
    "entropy_it = compute_entropy(df[\"LLaMA_IT\"])\n",
    "entropy_en = compute_entropy(df[\"LLaMA_EN\"])\n",
    "\n",
    "print(f\"Entropy (EN): {entropy_en:.3f}\")\n",
    "print(f\"Entropy (FA): {entropy_fa:.3f}\")\n",
    "print(f\"Entropy (IT): {entropy_it:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2369fd5-63d3-43fa-83a9-9d5b6bcee51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy (EN): 1.929\n",
      "Entropy (FA): 1.743\n",
      "Entropy (IT): 1.929\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your merged DataFrame, e.g., for GPT-4o\n",
    "df = pd.read_csv(\"Qwen2.5_Merged_Multilingual.csv\")\n",
    "\n",
    "def compute_entropy(series):\n",
    "    counts = series.value_counts(normalize=True)\n",
    "    entropy = -np.sum(counts * np.log2(counts))\n",
    "    return entropy\n",
    "\n",
    "# Entropy for Persian (FA), Italian (IT), and English (EN)\n",
    "entropy_fa = compute_entropy(df[\"Qwen2.5_FA\"])\n",
    "entropy_it = compute_entropy(df[\"Qwen2.5_IT\"])\n",
    "entropy_en = compute_entropy(df[\"Qwen2.5_EN\"])\n",
    "\n",
    "print(f\"Entropy (EN): {entropy_en:.3f}\")\n",
    "print(f\"Entropy (FA): {entropy_fa:.3f}\")\n",
    "print(f\"Entropy (IT): {entropy_it:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad2643ef-3a6e-49c4-a403-109cc4acd268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy (EN): 1.680\n",
      "Entropy (FA): 1.731\n",
      "Entropy (IT): 1.955\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your merged DataFrame, e.g., for GPT-4o\n",
    "df = pd.read_csv(\"XLM-R_Merged_Multilingual.csv\")\n",
    "\n",
    "def compute_entropy(series):\n",
    "    counts = series.value_counts(normalize=True)\n",
    "    entropy = -np.sum(counts * np.log2(counts))\n",
    "    return entropy\n",
    "\n",
    "# Entropy for Persian (FA), Italian (IT), and English (EN)\n",
    "entropy_fa = compute_entropy(df[\"XLMR_FA\"])\n",
    "entropy_it = compute_entropy(df[\"XLMR_IT\"])\n",
    "entropy_en = compute_entropy(df[\"XLMR_EN\"])\n",
    "\n",
    "print(f\"Entropy (EN): {entropy_en:.3f}\")\n",
    "print(f\"Entropy (FA): {entropy_fa:.3f}\")\n",
    "print(f\"Entropy (IT): {entropy_it:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47ec3459-0c8d-4237-ba1f-541900ee3aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy (EN): 1.420\n",
      "Entropy (FA): 1.980\n",
      "Entropy (IT): 1.928\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your merged DataFrame, e.g., for GPT-4o\n",
    "df = pd.read_csv(\"mBERT_Merged_Multilingual.csv\")\n",
    "\n",
    "def compute_entropy(series):\n",
    "    counts = series.value_counts(normalize=True)\n",
    "    entropy = -np.sum(counts * np.log2(counts))\n",
    "    return entropy\n",
    "\n",
    "# Entropy for Persian (FA), Italian (IT), and English (EN)\n",
    "entropy_fa = compute_entropy(df[\"mBERT_FA\"])\n",
    "entropy_it = compute_entropy(df[\"mBERT_IT\"])\n",
    "entropy_en = compute_entropy(df[\"mBERT_EN\"])\n",
    "\n",
    "print(f\"Entropy (EN): {entropy_en:.3f}\")\n",
    "print(f\"Entropy (FA): {entropy_fa:.3f}\")\n",
    "print(f\"Entropy (IT): {entropy_it:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8082f71d-a979-4ecc-9417-9717d33f33b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Model Lang  Entropy Mean  CI Lower  CI Upper\n",
      "0      GPT-4o   EN         1.857     1.691     1.968\n",
      "1      GPT-4o   FA         1.886     1.733     1.984\n",
      "2      GPT-4o   IT         1.932     1.803     1.995\n",
      "3   LLaMA 3.1   EN         1.952     1.866     1.997\n",
      "4   LLaMA 3.1   FA         1.936     1.803     1.994\n",
      "5   LLaMA 3.1   IT         1.843     1.672     1.955\n",
      "6   LLaMA 3.2   EN         1.800     1.578     1.945\n",
      "7   LLaMA 3.2   FA         1.769     1.584     1.905\n",
      "8   LLaMA 3.2   IT         1.867     1.709     1.975\n",
      "9     Qwen2.5   EN         1.895     1.738     1.988\n",
      "10    Qwen2.5   FA         1.707     1.497     1.885\n",
      "11    Qwen2.5   IT         1.892     1.739     1.985\n",
      "12      mBERT   EN         1.378     1.136     1.595\n",
      "13      mBERT   FA         1.943     1.831     1.995\n",
      "14      mBERT   IT         1.891     1.730     1.984\n",
      "15      XLM-R   EN         1.642     1.385     1.825\n",
      "16      XLM-R   FA         1.694     1.430     1.896\n",
      "17      XLM-R   IT         1.922     1.805     1.989\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def compute_entropy(series):\n",
    "    probs = series.value_counts(normalize=True)\n",
    "    return -np.sum(probs * np.log2(probs + 1e-9))  # small epsilon to avoid log(0)\n",
    "\n",
    "def bootstrap_entropy_CI(series, n_bootstrap=1000, confidence=0.95):\n",
    "    bootstrapped = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        sample = series.sample(frac=1.0, replace=True)\n",
    "        bootstrapped.append(compute_entropy(sample))\n",
    "    lower = np.percentile(bootstrapped, (1 - confidence) / 2 * 100)\n",
    "    upper = np.percentile(bootstrapped, (1 + confidence) / 2 * 100)\n",
    "    mean = np.mean(bootstrapped)\n",
    "    return mean, lower, upper\n",
    "\n",
    "# Define your LLMs and their corresponding CSVs and column prefixes\n",
    "models = {\n",
    "    \"GPT-4o\":     (\"GPT4o_Merged_Multilingual.csv\", \"GPT4o\"),\n",
    "    \"LLaMA 3.1\":  (\"LLaMA3.1_70_Merged_Multilingual.csv\", \"LLaMA3.1\"),\n",
    "    \"LLaMA 3.2\":  (\"LLaMA3.2_Merged_Multilingual.csv\", \"LLaMA\"),\n",
    "    \"Qwen2.5\":    (\"Qwen2.5_Merged_Multilingual.csv\", \"Qwen2.5\"),\n",
    "    \"mBERT\":      (\"mBERT_Merged_Multilingual.csv\", \"mBERT\"),\n",
    "    \"XLM-R\":      (\"XLM-R_Merged_Multilingual.csv\", \"XLMR\"),\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, (filepath, prefix) in models.items():\n",
    "    df = pd.read_csv(filepath)\n",
    "    for lang in [\"EN\", \"FA\", \"IT\"]:\n",
    "        col = f\"{prefix}_{lang}\"\n",
    "        mean, low, high = bootstrap_entropy_CI(df[col])\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Lang\": lang,\n",
    "            \"Entropy Mean\": round(mean, 3),\n",
    "            \"CI Lower\": round(low, 3),\n",
    "            \"CI Upper\": round(high, 3)\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "entropy_df = pd.DataFrame(results)\n",
    "print(entropy_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d16c5d9-6be3-46df-ba06-8b7ba3af190c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
