{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c7946d-7626-4a9d-9910-8b7a2eefa814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Full agreement across EN, FA, IT: 8.33%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load merged mBERT output\n",
    "df = pd.read_csv(\"XLM-R_Merged_Multilingual.csv\")\n",
    "\n",
    "# Check if all three predictions agree\n",
    "df[\"All_Agree\"] = (\n",
    "    (df[\"XLMR_EN\"] == df[\"XLMR_FA\"]) &\n",
    "    (df[\"XLMR_EN\"] == df[\"XLMR_IT\"])\n",
    ")\n",
    "\n",
    "# Calculate agreement rate\n",
    "agreement_rate = df[\"All_Agree\"].mean() * 100\n",
    "print(f\"‚úÖ Full agreement across EN, FA, IT: {agreement_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52531166-3373-44e4-9454-54977f4aac37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain_EN\n",
      "Activism & Social Change    5\n",
      "Arts & Culture              5\n",
      "Business & Economics        3\n",
      "Caregiving & Parenting      5\n",
      "Education                   4\n",
      "Healthcare                  5\n",
      "Hospitality & Service       4\n",
      "Journalism & Media          5\n",
      "Law & Justice               5\n",
      "Politics & Leadership       5\n",
      "Religion & Spirituality     5\n",
      "Science & Technology        4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df[\"Disagree\"] = ~df[\"All_Agree\"]\n",
    "disagreements_by_domain = df[df[\"Disagree\"]].groupby(\"Domain_EN\").size()\n",
    "print(disagreements_by_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3261dbd-7d85-4294-a477-7c779e17c524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disagreement_Type\n",
      "All different    26\n",
      "IT diverged      12\n",
      "EN diverged      11\n",
      "FA diverged      11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the merged mBERT output\n",
    "df = pd.read_csv(\"XLM-R_Merged_Multilingual.csv\")\n",
    "\n",
    "# Add Disagreement_Type column for mBERT\n",
    "df[\"Disagreement_Type\"] = df.apply(lambda row: \n",
    "    \"FA diverged\" if row[\"XLMR_EN\"] == row[\"XLMR_IT\"] != row[\"XLMR_FA\"] else\n",
    "    \"IT diverged\" if row[\"XLMR_EN\"] == row[\"XLMR_FA\"] != row[\"XLMR_IT\"] else\n",
    "    \"EN diverged\" if row[\"XLMR_FA\"] == row[\"XLMR_IT\"] != row[\"XLMR_EN\"] else\n",
    "    \"All different\", axis=1\n",
    ")\n",
    "\n",
    "# Print the disagreement breakdown\n",
    "print(df[\"Disagreement_Type\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00e76802-f33f-4d79-b2cb-3f1204d07afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option frequency in FA:\n",
      "XLMR_FA\n",
      "B    52.0\n",
      "D    23.0\n",
      "A    13.0\n",
      "C    12.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Option frequency in FA:\")\n",
    "print(df[\"XLMR_FA\"].value_counts(normalize=True).round(2) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8ca4ca5-7f37-46a3-a2f3-23a0730eea71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Exported 55 disagreement cases to mBERT_Disagreements.csv\n",
      "‚úÖ Saved domain-wise disagreement counts to XLMR_Disagreement_By_Domain.csv\n",
      "\n",
      "üìä Top domains with most disagreement:\n",
      "                     Domain  Disagreement_Count\n",
      "0     Politics & Leadership                   5\n",
      "1                Healthcare                   5\n",
      "2            Arts & Culture                   5\n",
      "3             Law & Justice                   5\n",
      "4    Caregiving & Parenting                   5\n",
      "5  Activism & Social Change                   5\n",
      "6        Journalism & Media                   5\n",
      "7   Religion & Spirituality                   5\n",
      "8      Science & Technology                   4\n",
      "9                 Education                   4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your aligned mBERT results\n",
    "df = pd.read_csv(\"XLM-R_Merged_Multilingual.csv\")\n",
    "\n",
    "# Identify disagreement rows (not all 3 agree)\n",
    "df[\"Disagreement\"] = (df[\"XLMR_EN\"] != df[\"XLMR_FA\"]) | \\\n",
    "                     (df[\"XLMR_EN\"] != df[\"XLMR_IT\"]) | \\\n",
    "                     (df[\"XLMR_FA\"] != df[\"XLMR_IT\"])\n",
    "\n",
    "# Export only the rows with disagreement\n",
    "df_disagreement = df[df[\"Disagreement\"] == True]\n",
    "df_disagreement.to_csv(\"XLMR_Disagreements.csv\", index=False)\n",
    "print(f\"‚úÖ Exported {len(df_disagreement)} disagreement cases to mBERT_Disagreements.csv\")\n",
    "\n",
    "# Count disagreement cases per domain\n",
    "disagreement_by_domain = df_disagreement[\"Domain_EN\"].value_counts().reset_index()\n",
    "disagreement_by_domain.columns = [\"Domain\", \"Disagreement_Count\"]\n",
    "disagreement_by_domain.to_csv(\"XLMR_Disagreement_By_Domain.csv\", index=False)\n",
    "print(\"‚úÖ Saved domain-wise disagreement counts to XLMR_Disagreement_By_Domain.csv\")\n",
    "\n",
    "# (Optional) Show most frequent disagreement domains in console\n",
    "print(\"\\nüìä Top domains with most disagreement:\")\n",
    "print(disagreement_by_domain.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b0a077e-1d8a-470a-8739-32ac4383fbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Full Agreement Rate:\n",
      "5/60 prompts (8.33%)\n",
      "\n",
      "üß© Disagreement Types:\n",
      "                   count\n",
      "Disagreement_Type       \n",
      "All different         21\n",
      "IT diverged           12\n",
      "EN diverged           11\n",
      "FA diverged           11\n",
      "All same               5 \n",
      "\n",
      "üó≥Ô∏è Option Frequency in Persian (XLMR_FA):\n",
      "         proportion\n",
      "XLMR_FA            \n",
      "B          0.516667\n",
      "D          0.233333\n",
      "A          0.133333\n",
      "C          0.116667 \n",
      "\n",
      "üåç Domain-wise Disagreements:\n",
      "                          count\n",
      "Domain_EN                      \n",
      "Politics & Leadership         5\n",
      "Healthcare                    5\n",
      "Arts & Culture                5\n",
      "Law & Justice                 5\n",
      "Caregiving & Parenting        5\n",
      "Activism & Social Change      5\n",
      "Journalism & Media            5\n",
      "Religion & Spirituality       5\n",
      "Science & Technology          4\n",
      "Education                     4\n",
      "Hospitality & Service         4\n",
      "Business & Economics          3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Load merged results file for mBERT\n",
    "df = pd.read_csv(\"XLM-R_Merged_Multilingual.csv\")\n",
    "\n",
    "# Check full agreement\n",
    "df[\"Full_Agreement\"] = (df[\"XLMR_EN\"] == df[\"XLMR_FA\"]) & (df[\"XLMR_EN\"] == df[\"XLMR_IT\"])\n",
    "\n",
    "# Classify type of disagreement\n",
    "def classify_disagreement(row):\n",
    "    choices = {row[\"XLMR_EN\"], row[\"XLMR_FA\"], row[\"XLMR_IT\"]}\n",
    "    if len(choices) == 1:\n",
    "        return \"All same\"\n",
    "    elif len(choices) == 3:\n",
    "        return \"All different\"\n",
    "    elif row[\"XLMR_EN\"] != row[\"XLMR_FA\"] and row[\"XLMR_EN\"] == row[\"XLMR_IT\"]:\n",
    "        return \"FA diverged\"\n",
    "    elif row[\"XLMR_EN\"] != row[\"XLMR_IT\"] and row[\"XLMR_EN\"] == row[\"XLMR_FA\"]:\n",
    "        return \"IT diverged\"\n",
    "    elif row[\"XLMR_EN\"] != row[\"XLMR_FA\"] and row[\"XLMR_FA\"] == row[\"XLMR_IT\"]:\n",
    "        return \"EN diverged\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "df[\"Disagreement_Type\"] = df.apply(classify_disagreement, axis=1)\n",
    "\n",
    "# Count full agreement\n",
    "agreement_count = df[\"Full_Agreement\"].sum()\n",
    "total = len(df)\n",
    "agreement_pct = agreement_count / total * 100\n",
    "\n",
    "# Disagreement breakdown\n",
    "disagreement_summary = df[\"Disagreement_Type\"].value_counts().to_frame(\"count\")\n",
    "\n",
    "# Frequency of choices in Persian\n",
    "fa_freq = df[\"XLMR_FA\"].value_counts(normalize=True).rename(\"proportion\").to_frame()\n",
    "\n",
    "# Domain-wise disagreement\n",
    "domain_disagreements = df[df[\"Disagreement_Type\"] != \"All same\"][\"Domain_EN\"].value_counts().to_frame(\"count\")\n",
    "\n",
    "# Display everything\n",
    "print(\"üîé Full Agreement Rate:\")\n",
    "print(f\"{agreement_count}/{total} prompts ({agreement_pct:.2f}%)\\n\")\n",
    "\n",
    "print(\"üß© Disagreement Types:\")\n",
    "print(disagreement_summary, \"\\n\")\n",
    "\n",
    "print(\"üó≥Ô∏è Option Frequency in Persian (XLMR_FA):\")\n",
    "print(fa_freq, \"\\n\")\n",
    "\n",
    "print(\"üåç Domain-wise Disagreements:\")\n",
    "print(domain_disagreements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89c15043-b117-487d-a2fc-73856838ee59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 95% CI for XLM-R agreement:\n",
      "Mean agreement: 8.37%\n",
      "95% Confidence Interval: [1.67%, 15.00%]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def bootstrap_xlmr_agreement_CI(filepath, prefix=\"XLMR\", num_bootstrap=1000, confidence=0.95):\n",
    "    df = pd.read_csv(filepath)\n",
    "    en, fa, it = f\"{prefix}_EN\", f\"{prefix}_FA\", f\"{prefix}_IT\"\n",
    "    df[\"Full_Agreement\"] = (df[en] == df[fa]) & (df[en] == df[it])\n",
    "\n",
    "    bootstrapped_agreements = []\n",
    "    for _ in range(num_bootstrap):\n",
    "        sample = df.sample(frac=1.0, replace=True)\n",
    "        agreement_pct = sample[\"Full_Agreement\"].mean() * 100\n",
    "        bootstrapped_agreements.append(agreement_pct)\n",
    "\n",
    "    lower_bound = np.percentile(bootstrapped_agreements, (1 - confidence) / 2 * 100)\n",
    "    upper_bound = np.percentile(bootstrapped_agreements, (1 + confidence) / 2 * 100)\n",
    "    mean_agreement = np.mean(bootstrapped_agreements)\n",
    "\n",
    "    print(f\"Bootstrapped {int(confidence*100)}% CI for XLM-R agreement:\")\n",
    "    print(f\"Mean agreement: {mean_agreement:.2f}%\")\n",
    "    print(f\"{int(confidence*100)}% Confidence Interval: [{lower_bound:.2f}%, {upper_bound:.2f}%]\")\n",
    "\n",
    "# Example usage:\n",
    "bootstrap_xlmr_agreement_CI(\"XLM-R_Merged_Multilingual.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "047618cd-eff1-4495-b7ac-6bdac2992067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 95% CI for XLMR disagreement:\n",
      "Mean disagreement: 91.75%\n",
      "95% Confidence Interval: [83.33%, 98.33%]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def bootstrap_xlmr_disagreement_CI(filepath, prefix=\"XLMR\", num_bootstrap=1000, confidence=0.95):\n",
    "    df = pd.read_csv(filepath)\n",
    "    en, fa, it = f\"{prefix}_EN\", f\"{prefix}_FA\", f\"{prefix}_IT\"\n",
    "    # Disagreement = NOT all three agree\n",
    "    df[\"Disagreement\"] = ~((df[en] == df[fa]) & (df[en] == df[it]))\n",
    "\n",
    "    bootstrapped_disagreements = []\n",
    "    for _ in range(num_bootstrap):\n",
    "        sample = df.sample(frac=1.0, replace=True)\n",
    "        disagreement_pct = sample[\"Disagreement\"].mean() * 100\n",
    "        bootstrapped_disagreements.append(disagreement_pct)\n",
    "\n",
    "    lower_bound = np.percentile(bootstrapped_disagreements, (1 - confidence) / 2 * 100)\n",
    "    upper_bound = np.percentile(bootstrapped_disagreements, (1 + confidence) / 2 * 100)\n",
    "    mean_disagreement = np.mean(bootstrapped_disagreements)\n",
    "\n",
    "    print(f\"Bootstrapped {int(confidence*100)}% CI for {prefix} disagreement:\")\n",
    "    print(f\"Mean disagreement: {mean_disagreement:.2f}%\")\n",
    "    print(f\"{int(confidence*100)}% Confidence Interval: [{lower_bound:.2f}%, {upper_bound:.2f}%]\")\n",
    "\n",
    "# Example usage:\n",
    "bootstrap_xlmr_disagreement_CI(\"XLM-R_Merged_Multilingual.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2edfb15-0a2a-40b2-bae9-991a577ba869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
