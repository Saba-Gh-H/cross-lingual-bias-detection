{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac79f87a-75c7-457f-b8c2-cd1b661f5704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Full agreement across EN, FA, IT: 23.33%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load merged LLaMA3.2 output\n",
    "df = pd.read_csv(\"LLaMA3.2_Merged_Multilingual.csv\")\n",
    "\n",
    "# Check if all three predictions agree\n",
    "df[\"All_Agree\"] = (\n",
    "    (df[\"LLaMA_EN\"] == df[\"LLaMA_FA\"]) &\n",
    "    (df[\"LLaMA_EN\"] == df[\"LLaMA_IT\"])\n",
    ")\n",
    "\n",
    "# Calculate agreement rate\n",
    "agreement_rate = df[\"All_Agree\"].mean() * 100\n",
    "print(f\"‚úÖ Full agreement across EN, FA, IT: {agreement_rate:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fba04bc-0c8e-497e-964d-e2577f291e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain_EN\n",
      "Activism & Social Change    5\n",
      "Arts & Culture              4\n",
      "Business & Economics        2\n",
      "Caregiving & Parenting      3\n",
      "Education                   3\n",
      "Healthcare                  4\n",
      "Hospitality & Service       4\n",
      "Journalism & Media          4\n",
      "Law & Justice               5\n",
      "Politics & Leadership       5\n",
      "Religion & Spirituality     4\n",
      "Science & Technology        3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df[\"Disagree\"] = ~df[\"All_Agree\"]\n",
    "disagreements_by_domain = df[df[\"Disagree\"]].groupby(\"Domain_EN\").size()\n",
    "print(disagreements_by_domain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17bf5768-2c00-47a5-be15-91ca2a2aad55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disagreement_Type\n",
      "All different    30\n",
      "FA diverged      14\n",
      "IT diverged      10\n",
      "EN diverged       6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the merged LLaMA 3.2 output\n",
    "df = pd.read_csv(\"LLaMA3.2_Merged_Multilingual.csv\")\n",
    "\n",
    "# Add Disagreement_Type column\n",
    "df[\"Disagreement_Type\"] = df.apply(lambda row: \n",
    "    \"FA diverged\" if row[\"LLaMA_EN\"] == row[\"LLaMA_IT\"] != row[\"LLaMA_FA\"] else\n",
    "    \"IT diverged\" if row[\"LLaMA_EN\"] == row[\"LLaMA_FA\"] != row[\"LLaMA_IT\"] else\n",
    "    \"EN diverged\" if row[\"LLaMA_FA\"] == row[\"LLaMA_IT\"] != row[\"LLaMA_EN\"] else\n",
    "    \"All different\", axis=1\n",
    ")\n",
    "\n",
    "# Print breakdown\n",
    "print(df[\"Disagreement_Type\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45d0f503-8d25-48b9-a8df-cd0546fd26c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option frequency in FA:\n",
      "LLaMA_FA\n",
      "C    37.0\n",
      "B    33.0\n",
      "D    23.0\n",
      "A     7.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Option frequency in FA:\")\n",
    "print(df[\"LLaMA_FA\"].value_counts(normalize=True).round(2) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f192a0d-4a2f-406b-8f97-7ad8226253d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Exported 46 disagreement cases to LLaMA3.2_Disagreements.csv\n",
      "‚úÖ Saved domain-wise disagreement counts to LLaMA3.2_Disagreement_By_Domain.csv\n",
      "\n",
      "üìä Top domains with most disagreement:\n",
      "                     Domain  Disagreement_Count\n",
      "0     Politics & Leadership                   5\n",
      "1             Law & Justice                   5\n",
      "2  Activism & Social Change                   5\n",
      "3                Healthcare                   4\n",
      "4     Hospitality & Service                   4\n",
      "5   Religion & Spirituality                   4\n",
      "6        Journalism & Media                   4\n",
      "7            Arts & Culture                   4\n",
      "8      Science & Technology                   3\n",
      "9                 Education                   3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your aligned LLaMA results\n",
    "df = pd.read_csv(\"LLaMA3.2_Merged_Multilingual.csv\")\n",
    "\n",
    "# Identify disagreement rows (not all 3 agree)\n",
    "df[\"Disagreement\"] = (df[\"LLaMA_EN\"] != df[\"LLaMA_FA\"]) | \\\n",
    "                     (df[\"LLaMA_EN\"] != df[\"LLaMA_IT\"]) | \\\n",
    "                     (df[\"LLaMA_FA\"] != df[\"LLaMA_IT\"])\n",
    "\n",
    "# Export only the rows with disagreement\n",
    "df_disagreement = df[df[\"Disagreement\"] == True]\n",
    "df_disagreement.to_csv(\"LLaMA3.2_Disagreements.csv\", index=False)\n",
    "print(f\"‚úÖ Exported {len(df_disagreement)} disagreement cases to LLaMA3.2_Disagreements.csv\")\n",
    "\n",
    "# Count disagreement cases per domain\n",
    "disagreement_by_domain = df_disagreement[\"Domain_EN\"].value_counts().reset_index()\n",
    "disagreement_by_domain.columns = [\"Domain\", \"Disagreement_Count\"]\n",
    "disagreement_by_domain.to_csv(\"LLaMA3.2_Disagreement_By_Domain.csv\", index=False)\n",
    "print(\"‚úÖ Saved domain-wise disagreement counts to LLaMA3.2_Disagreement_By_Domain.csv\")\n",
    "\n",
    "# (Optional) Show most frequent disagreement domains in console\n",
    "print(\"\\nüìä Top domains with most disagreement:\")\n",
    "print(disagreement_by_domain.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af616c81-a7c3-4951-9770-882649275218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Full Agreement Rate:\n",
      "14/60 prompts (23.33%)\n",
      "\n",
      "üß© Disagreement Types:\n",
      "                   count\n",
      "Disagreement_Type       \n",
      "All different         16\n",
      "FA diverged           14\n",
      "All same              14\n",
      "IT diverged           10\n",
      "EN diverged            6 \n",
      "\n",
      "üó≥Ô∏è Option Frequency in Persian (LLaMA_FA):\n",
      "          proportion\n",
      "LLaMA_FA            \n",
      "C           0.366667\n",
      "B           0.333333\n",
      "D           0.233333\n",
      "A           0.066667 \n",
      "\n",
      "üåç Domain-wise Disagreements:\n",
      "                          count\n",
      "Domain_EN                      \n",
      "Politics & Leadership         5\n",
      "Law & Justice                 5\n",
      "Activism & Social Change      5\n",
      "Healthcare                    4\n",
      "Hospitality & Service         4\n",
      "Religion & Spirituality       4\n",
      "Journalism & Media            4\n",
      "Arts & Culture                4\n",
      "Science & Technology          3\n",
      "Education                     3\n",
      "Caregiving & Parenting        3\n",
      "Business & Economics          2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Load merged results file for LLaMA 3.2\n",
    "df = pd.read_csv(\"LLaMA3.2_Merged_Multilingual.csv\")\n",
    "\n",
    "# Check full agreement\n",
    "df[\"Full_Agreement\"] = (df[\"LLaMA_EN\"] == df[\"LLaMA_FA\"]) & (df[\"LLaMA_EN\"] == df[\"LLaMA_IT\"])\n",
    "\n",
    "# Classify type of disagreement\n",
    "def classify_disagreement(row):\n",
    "    choices = {row[\"LLaMA_EN\"], row[\"LLaMA_FA\"], row[\"LLaMA_IT\"]}\n",
    "    if len(choices) == 1:\n",
    "        return \"All same\"\n",
    "    elif len(choices) == 3:\n",
    "        return \"All different\"\n",
    "    elif row[\"LLaMA_EN\"] != row[\"LLaMA_FA\"] and row[\"LLaMA_EN\"] == row[\"LLaMA_IT\"]:\n",
    "        return \"FA diverged\"\n",
    "    elif row[\"LLaMA_EN\"] != row[\"LLaMA_IT\"] and row[\"LLaMA_EN\"] == row[\"LLaMA_FA\"]:\n",
    "        return \"IT diverged\"\n",
    "    elif row[\"LLaMA_EN\"] != row[\"LLaMA_FA\"] and row[\"LLaMA_FA\"] == row[\"LLaMA_IT\"]:\n",
    "        return \"EN diverged\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "df[\"Disagreement_Type\"] = df.apply(classify_disagreement, axis=1)\n",
    "\n",
    "# Count full agreement\n",
    "agreement_count = df[\"Full_Agreement\"].sum()\n",
    "total = len(df)\n",
    "agreement_pct = agreement_count / total * 100\n",
    "\n",
    "# Disagreement breakdown\n",
    "disagreement_summary = df[\"Disagreement_Type\"].value_counts().to_frame(\"count\")\n",
    "\n",
    "# Frequency of choices in Persian\n",
    "fa_freq = df[\"LLaMA_FA\"].value_counts(normalize=True).rename(\"proportion\").to_frame()\n",
    "\n",
    "# Domain-wise disagreement\n",
    "domain_disagreements = df[df[\"Disagreement_Type\"] != \"All same\"][\"Domain_EN\"].value_counts().to_frame(\"count\")\n",
    "\n",
    "# Display everything\n",
    "print(\"üîé Full Agreement Rate:\")\n",
    "print(f\"{agreement_count}/{total} prompts ({agreement_pct:.2f}%)\\n\")\n",
    "\n",
    "print(\"üß© Disagreement Types:\")\n",
    "print(disagreement_summary, \"\\n\")\n",
    "\n",
    "print(\"üó≥Ô∏è Option Frequency in Persian (LLaMA_FA):\")\n",
    "print(fa_freq, \"\\n\")\n",
    "\n",
    "print(\"üåç Domain-wise Disagreements:\")\n",
    "print(domain_disagreements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc2c4aa3-9b23-42d0-b70a-b538433bebe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 95% CI for LLaMA 3.2 agreement:\n",
      "Mean agreement: 23.27%\n",
      "95% Confidence Interval: [13.33%, 35.00%]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def bootstrap_llama32_agreement_CI(filepath, prefix=\"LLaMA\", num_bootstrap=1000, confidence=0.95):\n",
    "    df = pd.read_csv(filepath)\n",
    "    en, fa, it = f\"{prefix}_EN\", f\"{prefix}_FA\", f\"{prefix}_IT\"\n",
    "    df[\"Full_Agreement\"] = (df[en] == df[fa]) & (df[en] == df[it])\n",
    "\n",
    "    bootstrapped_agreements = []\n",
    "    for _ in range(num_bootstrap):\n",
    "        sample = df.sample(frac=1.0, replace=True)\n",
    "        agreement_pct = sample[\"Full_Agreement\"].mean() * 100\n",
    "        bootstrapped_agreements.append(agreement_pct)\n",
    "\n",
    "    lower_bound = np.percentile(bootstrapped_agreements, (1 - confidence) / 2 * 100)\n",
    "    upper_bound = np.percentile(bootstrapped_agreements, (1 + confidence) / 2 * 100)\n",
    "    mean_agreement = np.mean(bootstrapped_agreements)\n",
    "\n",
    "    print(f\"Bootstrapped {int(confidence*100)}% CI for LLaMA 3.2 agreement:\")\n",
    "    print(f\"Mean agreement: {mean_agreement:.2f}%\")\n",
    "    print(f\"{int(confidence*100)}% Confidence Interval: [{lower_bound:.2f}%, {upper_bound:.2f}%]\")\n",
    "\n",
    "# Example usage:\n",
    "bootstrap_llama32_agreement_CI(\"LLaMA3.2_Merged_Multilingual.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14516ad6-00d6-4d41-b1a6-b598670fc61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 95% CI for LLaMA 3.2 disagreement:\n",
      "Mean disagreement: 76.83%\n",
      "95% Confidence Interval: [65.00%, 88.33%]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def bootstrap_llama32_disagreement_CI(filepath, prefix=\"LLaMA\", num_bootstrap=1000, confidence=0.95):\n",
    "    df = pd.read_csv(filepath)\n",
    "    en, fa, it = f\"{prefix}_EN\", f\"{prefix}_FA\", f\"{prefix}_IT\"\n",
    "\n",
    "    # Disagreement: at least one language differs\n",
    "    df[\"Disagreement\"] = (df[en] != df[fa]) | (df[en] != df[it]) | (df[fa] != df[it])\n",
    "\n",
    "    bootstrapped_disagreements = []\n",
    "    for _ in range(num_bootstrap):\n",
    "        sample = df.sample(frac=1.0, replace=True)\n",
    "        disagreement_pct = sample[\"Disagreement\"].mean() * 100\n",
    "        bootstrapped_disagreements.append(disagreement_pct)\n",
    "\n",
    "    lower_bound = np.percentile(bootstrapped_disagreements, (1 - confidence) / 2 * 100)\n",
    "    upper_bound = np.percentile(bootstrapped_disagreements, (1 + confidence) / 2 * 100)\n",
    "    mean_disagreement = np.mean(bootstrapped_disagreements)\n",
    "\n",
    "    print(f\"Bootstrapped {int(confidence*100)}% CI for LLaMA 3.2 disagreement:\")\n",
    "    print(f\"Mean disagreement: {mean_disagreement:.2f}%\")\n",
    "    print(f\"{int(confidence*100)}% Confidence Interval: [{lower_bound:.2f}%, {upper_bound:.2f}%]\")\n",
    "\n",
    "# Example usage:\n",
    "bootstrap_llama32_disagreement_CI(\"LLaMA3.2_Merged_Multilingual.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0b8bf4-579c-4af7-afbb-943690a3acdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
