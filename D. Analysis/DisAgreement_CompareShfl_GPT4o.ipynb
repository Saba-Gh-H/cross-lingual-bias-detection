{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81a7105e-a696-40d1-a671-ef94da7e2401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Agreement (%)  All Different  FA Diverged  IT Diverged  \\\n",
      "GPT-4o Original           50.0              7           11            5   \n",
      "GPT-4o Shuffled           50.0              4           12            9   \n",
      "\n",
      "                 EN Diverged  A_FA (%)  B_FA (%)  C_FA (%)  D_FA (%)  \n",
      "GPT-4o Original            7     16.67     36.67     28.33     18.33  \n",
      "GPT-4o Shuffled            5     20.00     35.00     35.00     10.00  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compute_gpt_metrics(filepath, prefix):\n",
    "    df = pd.read_csv(filepath)\n",
    "    en, fa, it = f\"{prefix}_EN\", f\"{prefix}_FA\", f\"{prefix}_IT\"\n",
    "\n",
    "    df[\"Full_Agreement\"] = (df[en] == df[fa]) & (df[en] == df[it])\n",
    "\n",
    "    def classify_disagreement(row):\n",
    "        choices = {row[en], row[fa], row[it]}\n",
    "        if len(choices) == 1:\n",
    "            return \"All same\"\n",
    "        elif len(choices) == 3:\n",
    "            return \"All different\"\n",
    "        elif row[en] == row[it] and row[fa] != row[en]:\n",
    "            return \"FA diverged\"\n",
    "        elif row[en] == row[fa] and row[it] != row[en]:\n",
    "            return \"IT diverged\"\n",
    "        elif row[fa] == row[it] and row[en] != row[fa]:\n",
    "            return \"EN diverged\"\n",
    "        return \"Other\"\n",
    "\n",
    "    df[\"Disagreement_Type\"] = df.apply(classify_disagreement, axis=1)\n",
    "    fa_freq = df[fa].value_counts(normalize=True) * 100\n",
    "    disagreement_counts = df[\"Disagreement_Type\"].value_counts()\n",
    "    agreement_pct = df[\"Full_Agreement\"].mean() * 100\n",
    "\n",
    "    return {\n",
    "        \"Agreement (%)\": round(agreement_pct, 2),\n",
    "        \"All Different\": disagreement_counts.get(\"All different\", 0),\n",
    "        \"FA Diverged\": disagreement_counts.get(\"FA diverged\", 0),\n",
    "        \"IT Diverged\": disagreement_counts.get(\"IT diverged\", 0),\n",
    "        \"EN Diverged\": disagreement_counts.get(\"EN diverged\", 0),\n",
    "        \"A_FA (%)\": round(fa_freq.get(\"A\", 0), 2),\n",
    "        \"B_FA (%)\": round(fa_freq.get(\"B\", 0), 2),\n",
    "        \"C_FA (%)\": round(fa_freq.get(\"C\", 0), 2),\n",
    "        \"D_FA (%)\": round(fa_freq.get(\"D\", 0), 2),\n",
    "    }\n",
    "\n",
    "# Apply to both files\n",
    "original_results = compute_gpt_metrics(\"GPT4o_Merged_Multilingual.csv\", \"GPT4o\")\n",
    "shuffled_results = compute_gpt_metrics(\"GPT4o_Shuffled_Merged_Multilingual.csv\", \"GPT4o\")\n",
    "\n",
    "# Combine into one table\n",
    "df_comparison = pd.DataFrame(\n",
    "    [original_results, shuffled_results],\n",
    "    index=[\"GPT-4o Original\", \"GPT-4o Shuffled\"]\n",
    ")\n",
    "\n",
    "# Display\n",
    "print(df_comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0fc4522-b57d-4bd0-813b-506cb638dc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Comparison of agreement and option distribution between original and shuffled GPT-4o prompts.}\n",
      "\\label{tab:gpt4o_shuffled_vs_original}\n",
      "\\begin{tabular}{lccccccccc}\n",
      "\\toprule\n",
      "Model & Agreement (%) & All Different & FA Diverged & IT Diverged & EN Diverged & A_FA (%) & B_FA (%) & C_FA (%) & D_FA (%) \\\\\n",
      "\\midrule\n",
      "GPT-4o (Original) & 50.000000 & 7 & 11 & 5 & 7 & 16.670000 & 36.670000 & 28.330000 & 18.330000 \\\\\n",
      "GPT-4o (Shuffled) & 50.000000 & 4 & 12 & 9 & 5 & 20.000000 & 35.000000 & 35.000000 & 10.000000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "def compute_metrics(path, prefix):\n",
    "    df = pd.read_csv(path)\n",
    "    en, fa, it = f\"{prefix}_EN\", f\"{prefix}_FA\", f\"{prefix}_IT\"\n",
    "\n",
    "    df[\"Full_Agreement\"] = (df[en] == df[fa]) & (df[en] == df[it])\n",
    "\n",
    "    def classify_disagreement(row):\n",
    "        choices = {row[en], row[fa], row[it]}\n",
    "        if len(choices) == 1:\n",
    "            return \"All same\"\n",
    "        elif len(choices) == 3:\n",
    "            return \"All different\"\n",
    "        elif row[en] == row[it] and row[fa] != row[en]:\n",
    "            return \"FA diverged\"\n",
    "        elif row[en] == row[fa] and row[it] != row[en]:\n",
    "            return \"IT diverged\"\n",
    "        elif row[fa] == row[it] and row[en] != row[fa]:\n",
    "            return \"EN diverged\"\n",
    "        return \"Other\"\n",
    "\n",
    "    df[\"Disagreement_Type\"] = df.apply(classify_disagreement, axis=1)\n",
    "    fa_freq = df[fa].value_counts(normalize=True) * 100\n",
    "    disagreement_counts = df[\"Disagreement_Type\"].value_counts()\n",
    "    agreement_pct = df[\"Full_Agreement\"].mean() * 100\n",
    "\n",
    "    return {\n",
    "        \"Agreement (%)\": round(agreement_pct, 2),\n",
    "        \"All Different\": disagreement_counts.get(\"All different\", 0),\n",
    "        \"FA Diverged\": disagreement_counts.get(\"FA diverged\", 0),\n",
    "        \"IT Diverged\": disagreement_counts.get(\"IT diverged\", 0),\n",
    "        \"EN Diverged\": disagreement_counts.get(\"EN diverged\", 0),\n",
    "        \"A_FA (%)\": round(fa_freq.get(\"A\", 0), 2),\n",
    "        \"B_FA (%)\": round(fa_freq.get(\"B\", 0), 2),\n",
    "        \"C_FA (%)\": round(fa_freq.get(\"C\", 0), 2),\n",
    "        \"D_FA (%)\": round(fa_freq.get(\"D\", 0), 2),\n",
    "    }\n",
    "\n",
    "# Run on original and shuffled\n",
    "original = compute_metrics(\"GPT4o_Merged_Multilingual.csv\", \"GPT4o\")\n",
    "shuffled = compute_metrics(\"GPT4o_Shuffled_Merged_Multilingual.csv\", \"GPT4o\")\n",
    "\n",
    "# Combine into DataFrame\n",
    "df_latex = pd.DataFrame(\n",
    "    [original, shuffled],\n",
    "    index=[\"GPT-4o (Original)\", \"GPT-4o (Shuffled)\"]\n",
    ").reset_index().rename(columns={\"index\": \"Model\"})\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_code = df_latex.to_latex(\n",
    "    index=False,\n",
    "    caption=\"Comparison of agreement and option distribution between original and shuffled GPT-4o prompts.\",\n",
    "    label=\"tab:gpt4o_shuffled_vs_original\",\n",
    "    column_format=\"lccccccccc\"\n",
    ")\n",
    "\n",
    "# Print LaTeX code\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50db3a98-ec2f-404d-ac17-076be8ed5cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original GPT-4o:\n",
      "Bootstrapped 95% CI for agreement:\n",
      "Mean agreement: 49.90%\n",
      "95% Confidence Interval: [36.67%, 63.33%]\n",
      "\n",
      "Shuffled GPT-4o:\n",
      "Bootstrapped 95% CI for agreement:\n",
      "Mean agreement: 49.88%\n",
      "95% Confidence Interval: [38.33%, 61.67%]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def bootstrap_agreement_CI(filepath, prefix, num_bootstrap=1000, confidence=0.95):\n",
    "    df = pd.read_csv(filepath)\n",
    "    en, fa, it = f\"{prefix}_EN\", f\"{prefix}_FA\", f\"{prefix}_IT\"\n",
    "    df[\"Full_Agreement\"] = (df[en] == df[fa]) & (df[en] == df[it])\n",
    "\n",
    "    # Bootstrapping\n",
    "    bootstrapped_agreements = []\n",
    "    for _ in range(num_bootstrap):\n",
    "        sample = df.sample(frac=1.0, replace=True)\n",
    "        agreement_pct = sample[\"Full_Agreement\"].mean() * 100\n",
    "        bootstrapped_agreements.append(agreement_pct)\n",
    "\n",
    "    lower_bound = np.percentile(bootstrapped_agreements, (1 - confidence) / 2 * 100)\n",
    "    upper_bound = np.percentile(bootstrapped_agreements, (1 + confidence) / 2 * 100)\n",
    "    mean_agreement = np.mean(bootstrapped_agreements)\n",
    "\n",
    "    print(f\"Bootstrapped {int(confidence*100)}% CI for agreement:\")\n",
    "    print(f\"Mean agreement: {mean_agreement:.2f}%\")\n",
    "    print(f\"95% Confidence Interval: [{lower_bound:.2f}%, {upper_bound:.2f}%]\")\n",
    "\n",
    "# Example usage:\n",
    "print(\"\\nOriginal GPT-4o:\")\n",
    "bootstrap_agreement_CI(\"GPT4o_Merged_Multilingual.csv\", \"GPT4o\")\n",
    "\n",
    "print(\"\\nShuffled GPT-4o:\")\n",
    "bootstrap_agreement_CI(\"GPT4o_Shuffled_Merged_Multilingual.csv\", \"GPT4o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fb07fae-cb06-44d3-8376-c64bb97ee39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original GPT-4o:\n",
      "Bootstrapped 95% CI for full disagreement:\n",
      "Mean disagreement: 11.78%\n",
      "95% Confidence Interval: [5.00%, 20.00%]\n",
      "\n",
      "Shuffled GPT-4o:\n",
      "Bootstrapped 95% CI for full disagreement:\n",
      "Mean disagreement: 6.82%\n",
      "95% Confidence Interval: [1.67%, 13.33%]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def bootstrap_disagreement_CI(filepath, prefix, num_bootstrap=1000, confidence=0.95):\n",
    "    df = pd.read_csv(filepath)\n",
    "    en, fa, it = f\"{prefix}_EN\", f\"{prefix}_FA\", f\"{prefix}_IT\"\n",
    "    df[\"Full_Disagreement\"] = (df[en] != df[fa]) & (df[en] != df[it]) & (df[fa] != df[it])\n",
    "\n",
    "    # Bootstrapping\n",
    "    bootstrapped_disagreements = []\n",
    "    for _ in range(num_bootstrap):\n",
    "        sample = df.sample(frac=1.0, replace=True)\n",
    "        disagreement_pct = sample[\"Full_Disagreement\"].mean() * 100\n",
    "        bootstrapped_disagreements.append(disagreement_pct)\n",
    "\n",
    "    lower_bound = np.percentile(bootstrapped_disagreements, (1 - confidence) / 2 * 100)\n",
    "    upper_bound = np.percentile(bootstrapped_disagreements, (1 + confidence) / 2 * 100)\n",
    "    mean_disagreement = np.mean(bootstrapped_disagreements)\n",
    "\n",
    "    print(f\"Bootstrapped {int(confidence*100)}% CI for full disagreement:\")\n",
    "    print(f\"Mean disagreement: {mean_disagreement:.2f}%\")\n",
    "    print(f\"95% Confidence Interval: [{lower_bound:.2f}%, {upper_bound:.2f}%]\")\n",
    "\n",
    "# Example usage:\n",
    "print(\"\\nOriginal GPT-4o:\")\n",
    "bootstrap_disagreement_CI(\"GPT4o_Merged_Multilingual.csv\", \"GPT4o\")\n",
    "\n",
    "print(\"\\nShuffled GPT-4o:\")\n",
    "bootstrap_disagreement_CI(\"GPT4o_Shuffled_Merged_Multilingual.csv\", \"GPT4o\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6544f-22b7-4c76-a5de-e8614b204837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
