{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2afdbac-fd8a-44b5-a500-67ba16a44ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Full agreement across EN, FA, IT: 53.33%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load merged LLaMA 3.1 output\n",
    "df = pd.read_csv(\"LLaMA3.1_70_Merged_Multilingual.csv\")\n",
    "\n",
    "# Check if all three predictions agree (fixing column names)\n",
    "df[\"All_Agree\"] = (\n",
    "    (df[\"LLaMA3.1_EN\"] == df[\"LLaMA3.1_FA\"]) &\n",
    "    (df[\"LLaMA3.1_EN\"] == df[\"LLaMA3.1_IT\"])\n",
    ")\n",
    "\n",
    "# Calculate agreement rate\n",
    "agreement_rate = df[\"All_Agree\"].mean() * 100\n",
    "print(f\"‚úÖ Full agreement across EN, FA, IT: {agreement_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcbbbb6d-1207-4b15-b6d9-120cb7ba3d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain_EN\n",
      "Activism & Social Change    2\n",
      "Arts & Culture              1\n",
      "Business & Economics        3\n",
      "Caregiving & Parenting      2\n",
      "Education                   2\n",
      "Healthcare                  1\n",
      "Hospitality & Service       3\n",
      "Journalism & Media          4\n",
      "Law & Justice               4\n",
      "Politics & Leadership       2\n",
      "Religion & Spirituality     2\n",
      "Science & Technology        2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df[\"Disagree\"] = ~df[\"All_Agree\"]\n",
    "disagreements_by_domain = df[df[\"Disagree\"]].groupby(\"Domain_EN\").size()\n",
    "print(disagreements_by_domain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "592a31f7-f16a-4184-9467-91d6c9382441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disagreement_Type\n",
      "All different    36\n",
      "IT diverged      13\n",
      "EN diverged       6\n",
      "FA diverged       5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the merged LLaMA 3.1 output\n",
    "df = pd.read_csv(\"LLaMA3.1_70_Merged_Multilingual.csv\")\n",
    "\n",
    "# Add Disagreement_Type column (fixing column names)\n",
    "df[\"Disagreement_Type\"] = df.apply(lambda row: \n",
    "    \"FA diverged\" if row[\"LLaMA3.1_EN\"] == row[\"LLaMA3.1_IT\"] != row[\"LLaMA3.1_FA\"] else\n",
    "    \"IT diverged\" if row[\"LLaMA3.1_EN\"] == row[\"LLaMA3.1_FA\"] != row[\"LLaMA3.1_IT\"] else\n",
    "    \"EN diverged\" if row[\"LLaMA3.1_FA\"] == row[\"LLaMA3.1_IT\"] != row[\"LLaMA3.1_EN\"] else\n",
    "    \"All different\", axis=1\n",
    ")\n",
    "\n",
    "# Print breakdown\n",
    "print(df[\"Disagreement_Type\"].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfbe10c9-502c-4331-93a3-43def8cf6248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option frequency in FA:\n",
      "LLaMA3.1_FA\n",
      "B    33.0\n",
      "C    23.0\n",
      "D    23.0\n",
      "A    20.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Option frequency in FA:\")\n",
    "print(df[\"LLaMA3.1_FA\"].value_counts(normalize=True).round(2) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "091dc040-3b04-4dce-a676-2ac5145bed2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Exported 28 disagreement cases to LLaMA3.1_Disagreements.csv\n",
      "‚úÖ Saved domain-wise disagreement counts to LLaMA3.1_Disagreement_By_Domain.csv\n",
      "\n",
      "üìä Top domains with most disagreement:\n",
      "                     Domain  Disagreement_Count\n",
      "0        Journalism & Media                   4\n",
      "1             Law & Justice                   4\n",
      "2     Hospitality & Service                   3\n",
      "3      Business & Economics                   3\n",
      "4  Activism & Social Change                   2\n",
      "5      Science & Technology                   2\n",
      "6                 Education                   2\n",
      "7     Politics & Leadership                   2\n",
      "8    Caregiving & Parenting                   2\n",
      "9   Religion & Spirituality                   2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your aligned LLaMA 3.1 results\n",
    "df = pd.read_csv(\"LLaMA3.1_70_Merged_Multilingual.csv\")\n",
    "\n",
    "# Identify disagreement rows (not all 3 agree)\n",
    "df[\"Disagreement\"] = (df[\"LLaMA3.1_EN\"] != df[\"LLaMA3.1_FA\"]) | \\\n",
    "                     (df[\"LLaMA3.1_EN\"] != df[\"LLaMA3.1_IT\"]) | \\\n",
    "                     (df[\"LLaMA3.1_FA\"] != df[\"LLaMA3.1_IT\"])\n",
    "\n",
    "# Export only rows with disagreement\n",
    "df_disagreement = df[df[\"Disagreement\"] == True]\n",
    "df_disagreement.to_csv(\"LLaMA3.1_Disagreements.csv\", index=False)\n",
    "print(f\"‚úÖ Exported {len(df_disagreement)} disagreement cases to LLaMA3.1_Disagreements.csv\")\n",
    "\n",
    "# Count disagreement cases per domain\n",
    "disagreement_by_domain = df_disagreement[\"Domain_EN\"].value_counts().reset_index()\n",
    "disagreement_by_domain.columns = [\"Domain\", \"Disagreement_Count\"]\n",
    "disagreement_by_domain.to_csv(\"LLaMA3.1_Disagreement_By_Domain.csv\", index=False)\n",
    "print(\"‚úÖ Saved domain-wise disagreement counts to LLaMA3.1_Disagreement_By_Domain.csv\")\n",
    "\n",
    "# Show top domains with most disagreement\n",
    "print(\"\\nüìä Top domains with most disagreement:\")\n",
    "print(disagreement_by_domain.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "128d1975-f659-4eb7-8456-69f4dfe359ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Full Agreement Rate:\n",
      "32/60 prompts (53.33%)\n",
      "\n",
      "üß© Disagreement Types:\n",
      "                   count\n",
      "Disagreement_Type       \n",
      "All same              32\n",
      "IT diverged           13\n",
      "EN diverged            6\n",
      "FA diverged            5\n",
      "All different          4 \n",
      "\n",
      "üó≥Ô∏è Option Frequency in Persian (LLaMA3.1_FA):\n",
      "             proportion\n",
      "LLaMA3.1_FA            \n",
      "B              0.333333\n",
      "C              0.233333\n",
      "D              0.233333\n",
      "A              0.200000 \n",
      "\n",
      "üåç Domain-wise Disagreements:\n",
      "                          count\n",
      "Domain_EN                      \n",
      "Journalism & Media            4\n",
      "Law & Justice                 4\n",
      "Hospitality & Service         3\n",
      "Business & Economics          3\n",
      "Activism & Social Change      2\n",
      "Science & Technology          2\n",
      "Education                     2\n",
      "Politics & Leadership         2\n",
      "Caregiving & Parenting        2\n",
      "Religion & Spirituality       2\n",
      "Healthcare                    1\n",
      "Arts & Culture                1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Load merged results file for LLaMA 3.1\n",
    "df = pd.read_csv(\"LLaMA3.1_70_Merged_Multilingual.csv\")\n",
    "\n",
    "# Check full agreement\n",
    "df[\"Full_Agreement\"] = (df[\"LLaMA3.1_EN\"] == df[\"LLaMA3.1_FA\"]) & (df[\"LLaMA3.1_EN\"] == df[\"LLaMA3.1_IT\"])\n",
    "\n",
    "# Classify type of disagreement\n",
    "def classify_disagreement(row):\n",
    "    choices = {row[\"LLaMA3.1_EN\"], row[\"LLaMA3.1_FA\"], row[\"LLaMA3.1_IT\"]}\n",
    "    if len(choices) == 1:\n",
    "        return \"All same\"\n",
    "    elif len(choices) == 3:\n",
    "        return \"All different\"\n",
    "    elif row[\"LLaMA3.1_EN\"] != row[\"LLaMA3.1_FA\"] and row[\"LLaMA3.1_EN\"] == row[\"LLaMA3.1_IT\"]:\n",
    "        return \"FA diverged\"\n",
    "    elif row[\"LLaMA3.1_EN\"] != row[\"LLaMA3.1_IT\"] and row[\"LLaMA3.1_EN\"] == row[\"LLaMA3.1_FA\"]:\n",
    "        return \"IT diverged\"\n",
    "    elif row[\"LLaMA3.1_EN\"] != row[\"LLaMA3.1_FA\"] and row[\"LLaMA3.1_FA\"] == row[\"LLaMA3.1_IT\"]:\n",
    "        return \"EN diverged\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "df[\"Disagreement_Type\"] = df.apply(classify_disagreement, axis=1)\n",
    "\n",
    "# Count full agreement\n",
    "agreement_count = df[\"Full_Agreement\"].sum()\n",
    "total = len(df)\n",
    "agreement_pct = agreement_count / total * 100\n",
    "\n",
    "# Disagreement breakdown\n",
    "disagreement_summary = df[\"Disagreement_Type\"].value_counts().to_frame(\"count\")\n",
    "\n",
    "# Frequency of choices in Persian\n",
    "fa_freq = df[\"LLaMA3.1_FA\"].value_counts(normalize=True).rename(\"proportion\").to_frame()\n",
    "\n",
    "# Domain-wise disagreement\n",
    "domain_disagreements = df[df[\"Disagreement_Type\"] != \"All same\"][\"Domain_EN\"].value_counts().to_frame(\"count\")\n",
    "\n",
    "# Display everything\n",
    "print(\"üîé Full Agreement Rate:\")\n",
    "print(f\"{agreement_count}/{total} prompts ({agreement_pct:.2f}%)\\n\")\n",
    "\n",
    "print(\"üß© Disagreement Types:\")\n",
    "print(disagreement_summary, \"\\n\")\n",
    "\n",
    "print(\"üó≥Ô∏è Option Frequency in Persian (LLaMA3.1_FA):\")\n",
    "print(fa_freq, \"\\n\")\n",
    "\n",
    "print(\"üåç Domain-wise Disagreements:\")\n",
    "print(domain_disagreements)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1476e41-bd4e-4de3-ad87-e61c3d47975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 95% CI for LLaMA 3.1 agreement:\n",
      "Mean agreement: 53.33%\n",
      "95% Confidence Interval: [41.67%, 65.00%]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def bootstrap_llama31_agreement_CI(filepath, prefix=\"LLaMA3.1\", num_bootstrap=1000, confidence=0.95):\n",
    "    df = pd.read_csv(filepath)\n",
    "    en, fa, it = f\"{prefix}_EN\", f\"{prefix}_FA\", f\"{prefix}_IT\"\n",
    "    df[\"Full_Agreement\"] = (df[en] == df[fa]) & (df[en] == df[it])\n",
    "\n",
    "    bootstrapped_agreements = []\n",
    "    for _ in range(num_bootstrap):\n",
    "        sample = df.sample(frac=1.0, replace=True)\n",
    "        agreement_pct = sample[\"Full_Agreement\"].mean() * 100\n",
    "        bootstrapped_agreements.append(agreement_pct)\n",
    "\n",
    "    lower_bound = np.percentile(bootstrapped_agreements, (1 - confidence) / 2 * 100)\n",
    "    upper_bound = np.percentile(bootstrapped_agreements, (1 + confidence) / 2 * 100)\n",
    "    mean_agreement = np.mean(bootstrapped_agreements)\n",
    "\n",
    "    print(f\"Bootstrapped {int(confidence*100)}% CI for LLaMA 3.1 agreement:\")\n",
    "    print(f\"Mean agreement: {mean_agreement:.2f}%\")\n",
    "    print(f\"{int(confidence*100)}% Confidence Interval: [{lower_bound:.2f}%, {upper_bound:.2f}%]\")\n",
    "\n",
    "# Example usage:\n",
    "bootstrap_llama31_agreement_CI(\"LLaMA3.1_70_Merged_Multilingual.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03099b6d-58f7-4d81-a548-a39c20963886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 95% CI for LLaMA 3.1 disagreement:\n",
      "Mean disagreement: 46.25%\n",
      "95% Confidence Interval: [33.33%, 60.00%]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def bootstrap_llama31_disagreement_CI(filepath, prefix=\"LLaMA3.1\", num_bootstrap=1000, confidence=0.95):\n",
    "    df = pd.read_csv(filepath)\n",
    "    en, fa, it = f\"{prefix}_EN\", f\"{prefix}_FA\", f\"{prefix}_IT\"\n",
    "\n",
    "    # Disagreement is when not all three match\n",
    "    df[\"Disagreement\"] = (df[en] != df[fa]) | (df[en] != df[it]) | (df[fa] != df[it])\n",
    "\n",
    "    bootstrapped_disagreements = []\n",
    "    for _ in range(num_bootstrap):\n",
    "        sample = df.sample(frac=1.0, replace=True)\n",
    "        disagreement_pct = sample[\"Disagreement\"].mean() * 100\n",
    "        bootstrapped_disagreements.append(disagreement_pct)\n",
    "\n",
    "    lower_bound = np.percentile(bootstrapped_disagreements, (1 - confidence) / 2 * 100)\n",
    "    upper_bound = np.percentile(bootstrapped_disagreements, (1 + confidence) / 2 * 100)\n",
    "    mean_disagreement = np.mean(bootstrapped_disagreements)\n",
    "\n",
    "    print(f\"Bootstrapped {int(confidence*100)}% CI for LLaMA 3.1 disagreement:\")\n",
    "    print(f\"Mean disagreement: {mean_disagreement:.2f}%\")\n",
    "    print(f\"{int(confidence*100)}% Confidence Interval: [{lower_bound:.2f}%, {upper_bound:.2f}%]\")\n",
    "\n",
    "# Example usage\n",
    "bootstrap_llama31_disagreement_CI(\"LLaMA3.1_70_Merged_Multilingual.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6487c85-cbb1-4a8a-81fe-8614eecd9679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
