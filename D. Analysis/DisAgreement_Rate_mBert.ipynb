{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8487f010-9329-4e23-b8d1-924130b82e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Full agreement across EN, FA, IT: 3.33%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load merged mBERT output\n",
    "df = pd.read_csv(\"mBERT_Merged_Multilingual.csv\")\n",
    "\n",
    "# Check if all three predictions agree\n",
    "df[\"All_Agree\"] = (\n",
    "    (df[\"mBERT_EN\"] == df[\"mBERT_FA\"]) &\n",
    "    (df[\"mBERT_EN\"] == df[\"mBERT_IT\"])\n",
    ")\n",
    "\n",
    "# Calculate agreement rate\n",
    "agreement_rate = df[\"All_Agree\"].mean() * 100\n",
    "print(f\"‚úÖ Full agreement across EN, FA, IT: {agreement_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ac5472d-c3c4-48fa-a2e3-f5e14d3e1c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain_EN\n",
      "Activism & Social Change    5\n",
      "Arts & Culture              4\n",
      "Business & Economics        5\n",
      "Caregiving & Parenting      5\n",
      "Education                   5\n",
      "Healthcare                  5\n",
      "Hospitality & Service       5\n",
      "Journalism & Media          5\n",
      "Law & Justice               5\n",
      "Politics & Leadership       5\n",
      "Religion & Spirituality     4\n",
      "Science & Technology        5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df[\"Disagree\"] = ~df[\"All_Agree\"]\n",
    "disagreements_by_domain = df[df[\"Disagree\"]].groupby(\"Domain_EN\").size()\n",
    "print(disagreements_by_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e0ee11-1d6f-4b2e-834c-4fce7fc78fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disagreement_Type\n",
      "All different    23\n",
      "FA diverged      14\n",
      "EN diverged      13\n",
      "IT diverged      10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the merged mBERT output\n",
    "df = pd.read_csv(\"mBERT_Merged_Multilingual.csv\")\n",
    "\n",
    "# Add Disagreement_Type column for mBERT\n",
    "df[\"Disagreement_Type\"] = df.apply(lambda row: \n",
    "    \"FA diverged\" if row[\"mBERT_EN\"] == row[\"mBERT_IT\"] != row[\"mBERT_FA\"] else\n",
    "    \"IT diverged\" if row[\"mBERT_EN\"] == row[\"mBERT_FA\"] != row[\"mBERT_IT\"] else\n",
    "    \"EN diverged\" if row[\"mBERT_FA\"] == row[\"mBERT_IT\"] != row[\"mBERT_EN\"] else\n",
    "    \"All different\", axis=1\n",
    ")\n",
    "\n",
    "# Print the disagreement breakdown\n",
    "print(df[\"Disagreement_Type\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a73765c-3d5a-430f-aeab-1dccfe413222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option frequency in FA:\n",
      "mBERT_FA\n",
      "B    28.0\n",
      "D    28.0\n",
      "C    25.0\n",
      "A    18.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Option frequency in FA:\")\n",
    "print(df[\"mBERT_FA\"].value_counts(normalize=True).round(2) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a47d8e1a-e645-4295-84a7-d75d6f795655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Exported 58 disagreement cases to mBERT_Disagreements.csv\n",
      "‚úÖ Saved domain-wise disagreement counts to mBERT_Disagreement_By_Domain.csv\n",
      "\n",
      "üìä Top domains with most disagreement:\n",
      "                     Domain  Disagreement_Count\n",
      "0     Politics & Leadership                   5\n",
      "1                 Education                   5\n",
      "2                Healthcare                   5\n",
      "3      Science & Technology                   5\n",
      "4      Business & Economics                   5\n",
      "5             Law & Justice                   5\n",
      "6        Journalism & Media                   5\n",
      "7  Activism & Social Change                   5\n",
      "8    Caregiving & Parenting                   5\n",
      "9     Hospitality & Service                   5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your aligned mBERT results\n",
    "df = pd.read_csv(\"mBERT_Merged_Multilingual.csv\")\n",
    "\n",
    "# Identify disagreement rows (not all 3 agree)\n",
    "df[\"Disagreement\"] = (df[\"mBERT_EN\"] != df[\"mBERT_FA\"]) | \\\n",
    "                     (df[\"mBERT_EN\"] != df[\"mBERT_IT\"]) | \\\n",
    "                     (df[\"mBERT_FA\"] != df[\"mBERT_IT\"])\n",
    "\n",
    "# Export only the rows with disagreement\n",
    "df_disagreement = df[df[\"Disagreement\"] == True]\n",
    "df_disagreement.to_csv(\"mBERT_Disagreements.csv\", index=False)\n",
    "print(f\"‚úÖ Exported {len(df_disagreement)} disagreement cases to mBERT_Disagreements.csv\")\n",
    "\n",
    "# Count disagreement cases per domain\n",
    "disagreement_by_domain = df_disagreement[\"Domain_EN\"].value_counts().reset_index()\n",
    "disagreement_by_domain.columns = [\"Domain\", \"Disagreement_Count\"]\n",
    "disagreement_by_domain.to_csv(\"mBERT_Disagreement_By_Domain.csv\", index=False)\n",
    "print(\"‚úÖ Saved domain-wise disagreement counts to mBERT_Disagreement_By_Domain.csv\")\n",
    "\n",
    "# (Optional) Show most frequent disagreement domains in console\n",
    "print(\"\\nüìä Top domains with most disagreement:\")\n",
    "print(disagreement_by_domain.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aee32be-9001-448d-9d35-a5070511e92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Full Agreement Rate:\n",
      "2/60 prompts (3.33%)\n",
      "\n",
      "üß© Disagreement Types:\n",
      "                   count\n",
      "Disagreement_Type       \n",
      "All different         21\n",
      "FA diverged           14\n",
      "EN diverged           13\n",
      "IT diverged           10\n",
      "All same               2 \n",
      "\n",
      "üó≥Ô∏è Option Frequency in Persian (mBERT_FA):\n",
      "          proportion\n",
      "mBERT_FA            \n",
      "B           0.283333\n",
      "D           0.283333\n",
      "C           0.250000\n",
      "A           0.183333 \n",
      "\n",
      "üåç Domain-wise Disagreements:\n",
      "                          count\n",
      "Domain_EN                      \n",
      "Politics & Leadership         5\n",
      "Education                     5\n",
      "Healthcare                    5\n",
      "Science & Technology          5\n",
      "Business & Economics          5\n",
      "Law & Justice                 5\n",
      "Journalism & Media            5\n",
      "Activism & Social Change      5\n",
      "Caregiving & Parenting        5\n",
      "Hospitality & Service         5\n",
      "Arts & Culture                4\n",
      "Religion & Spirituality       4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Load merged results file for mBERT\n",
    "df = pd.read_csv(\"mBERT_Merged_Multilingual.csv\")\n",
    "\n",
    "# Check full agreement\n",
    "df[\"Full_Agreement\"] = (df[\"mBERT_EN\"] == df[\"mBERT_FA\"]) & (df[\"mBERT_EN\"] == df[\"mBERT_IT\"])\n",
    "\n",
    "# Classify type of disagreement\n",
    "def classify_disagreement(row):\n",
    "    choices = {row[\"mBERT_EN\"], row[\"mBERT_FA\"], row[\"mBERT_IT\"]}\n",
    "    if len(choices) == 1:\n",
    "        return \"All same\"\n",
    "    elif len(choices) == 3:\n",
    "        return \"All different\"\n",
    "    elif row[\"mBERT_EN\"] != row[\"mBERT_FA\"] and row[\"mBERT_EN\"] == row[\"mBERT_IT\"]:\n",
    "        return \"FA diverged\"\n",
    "    elif row[\"mBERT_EN\"] != row[\"mBERT_IT\"] and row[\"mBERT_EN\"] == row[\"mBERT_FA\"]:\n",
    "        return \"IT diverged\"\n",
    "    elif row[\"mBERT_EN\"] != row[\"mBERT_FA\"] and row[\"mBERT_FA\"] == row[\"mBERT_IT\"]:\n",
    "        return \"EN diverged\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "df[\"Disagreement_Type\"] = df.apply(classify_disagreement, axis=1)\n",
    "\n",
    "# Count full agreement\n",
    "agreement_count = df[\"Full_Agreement\"].sum()\n",
    "total = len(df)\n",
    "agreement_pct = agreement_count / total * 100\n",
    "\n",
    "# Disagreement breakdown\n",
    "disagreement_summary = df[\"Disagreement_Type\"].value_counts().to_frame(\"count\")\n",
    "\n",
    "# Frequency of choices in Persian\n",
    "fa_freq = df[\"mBERT_FA\"].value_counts(normalize=True).rename(\"proportion\").to_frame()\n",
    "\n",
    "# Domain-wise disagreement\n",
    "domain_disagreements = df[df[\"Disagreement_Type\"] != \"All same\"][\"Domain_EN\"].value_counts().to_frame(\"count\")\n",
    "\n",
    "# Display everything\n",
    "print(\"üîé Full Agreement Rate:\")\n",
    "print(f\"{agreement_count}/{total} prompts ({agreement_pct:.2f}%)\\n\")\n",
    "\n",
    "print(\"üß© Disagreement Types:\")\n",
    "print(disagreement_summary, \"\\n\")\n",
    "\n",
    "print(\"üó≥Ô∏è Option Frequency in Persian (mBERT_FA):\")\n",
    "print(fa_freq, \"\\n\")\n",
    "\n",
    "print(\"üåç Domain-wise Disagreements:\")\n",
    "print(domain_disagreements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26391e80-9932-464b-be60-55596bedbfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 95% CI for mBERT agreement:\n",
      "Mean agreement: 3.23%\n",
      "95% Confidence Interval: [0.00%, 8.33%]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def bootstrap_mbert_agreement_CI(filepath, prefix=\"mBERT\", num_bootstrap=1000, confidence=0.95):\n",
    "    df = pd.read_csv(filepath)\n",
    "    en, fa, it = f\"{prefix}_EN\", f\"{prefix}_FA\", f\"{prefix}_IT\"\n",
    "    df[\"Full_Agreement\"] = (df[en] == df[fa]) & (df[en] == df[it])\n",
    "\n",
    "    bootstrapped_agreements = []\n",
    "    for _ in range(num_bootstrap):\n",
    "        sample = df.sample(frac=1.0, replace=True)\n",
    "        agreement_pct = sample[\"Full_Agreement\"].mean() * 100\n",
    "        bootstrapped_agreements.append(agreement_pct)\n",
    "\n",
    "    lower_bound = np.percentile(bootstrapped_agreements, (1 - confidence) / 2 * 100)\n",
    "    upper_bound = np.percentile(bootstrapped_agreements, (1 + confidence) / 2 * 100)\n",
    "    mean_agreement = np.mean(bootstrapped_agreements)\n",
    "\n",
    "    print(f\"Bootstrapped {int(confidence*100)}% CI for mBERT agreement:\")\n",
    "    print(f\"Mean agreement: {mean_agreement:.2f}%\")\n",
    "    print(f\"{int(confidence*100)}% Confidence Interval: [{lower_bound:.2f}%, {upper_bound:.2f}%]\")\n",
    "\n",
    "# Example usage:\n",
    "bootstrap_mbert_agreement_CI(\"mBERT_Merged_Multilingual.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0f2a016-bddb-4c5f-827f-96ef108e2a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 95% CI for mBERT disagreement:\n",
      "Mean disagreement: 96.63%\n",
      "95% Confidence Interval: [91.67%, 100.00%]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def bootstrap_mbert_disagreement_CI(filepath, prefix=\"mBERT\", num_bootstrap=1000, confidence=0.95):\n",
    "    df = pd.read_csv(filepath)\n",
    "    en, fa, it = f\"{prefix}_EN\", f\"{prefix}_FA\", f\"{prefix}_IT\"\n",
    "    # Disagreement means not all three agree\n",
    "    df[\"Disagreement\"] = ~((df[en] == df[fa]) & (df[en] == df[it]))\n",
    "\n",
    "    bootstrapped_disagreements = []\n",
    "    for _ in range(num_bootstrap):\n",
    "        sample = df.sample(frac=1.0, replace=True)\n",
    "        disagreement_pct = sample[\"Disagreement\"].mean() * 100\n",
    "        bootstrapped_disagreements.append(disagreement_pct)\n",
    "\n",
    "    lower_bound = np.percentile(bootstrapped_disagreements, (1 - confidence) / 2 * 100)\n",
    "    upper_bound = np.percentile(bootstrapped_disagreements, (1 + confidence) / 2 * 100)\n",
    "    mean_disagreement = np.mean(bootstrapped_disagreements)\n",
    "\n",
    "    print(f\"Bootstrapped {int(confidence*100)}% CI for {prefix} disagreement:\")\n",
    "    print(f\"Mean disagreement: {mean_disagreement:.2f}%\")\n",
    "    print(f\"{int(confidence*100)}% Confidence Interval: [{lower_bound:.2f}%, {upper_bound:.2f}%]\")\n",
    "\n",
    "# Example usage:\n",
    "bootstrap_mbert_disagreement_CI(\"mBERT_Merged_Multilingual.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1974e86-495c-49b6-adcb-4c0ccd36f56d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
