{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db5836bb-c253-4cbe-b892-e0754912c0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Full agreement across EN, FA, IT: 50.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"GPT4o_Merged_Multilingual.csv\")\n",
    "\n",
    "df[\"All_Agree\"] = (\n",
    "    (df[\"GPT4o_EN\"] == df[\"GPT4o_FA\"]) &\n",
    "    (df[\"GPT4o_EN\"] == df[\"GPT4o_IT\"])\n",
    ")\n",
    "\n",
    "agreement_rate = df[\"All_Agree\"].mean() * 100\n",
    "print(f\"‚úÖ Full agreement across EN, FA, IT: {agreement_rate:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0beadfca-43db-437c-8e6c-be349b697ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain_EN\n",
      "Activism & Social Change    2\n",
      "Arts & Culture              1\n",
      "Business & Economics        1\n",
      "Caregiving & Parenting      2\n",
      "Education                   2\n",
      "Healthcare                  1\n",
      "Hospitality & Service       2\n",
      "Journalism & Media          3\n",
      "Law & Justice               5\n",
      "Politics & Leadership       4\n",
      "Religion & Spirituality     4\n",
      "Science & Technology        3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df[\"Disagree\"] = ~df[\"All_Agree\"]\n",
    "disagreements_by_domain = df[df[\"Disagree\"]].groupby(\"Domain_EN\").size()\n",
    "print(disagreements_by_domain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51146ef6-cd90-4ec0-a6db-48e428867e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disagreement_Type\n",
      "All different    37\n",
      "FA diverged      11\n",
      "EN diverged       7\n",
      "IT diverged       5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df[\"Disagreement_Type\"] = df.apply(lambda row: \n",
    "    \"FA diverged\" if row[\"GPT4o_EN\"] == row[\"GPT4o_IT\"] != row[\"GPT4o_FA\"] else\n",
    "    \"IT diverged\" if row[\"GPT4o_EN\"] == row[\"GPT4o_FA\"] != row[\"GPT4o_IT\"] else\n",
    "    \"EN diverged\" if row[\"GPT4o_FA\"] == row[\"GPT4o_IT\"] != row[\"GPT4o_EN\"] else\n",
    "    \"All different\", axis=1\n",
    ")\n",
    "\n",
    "print(df[\"Disagreement_Type\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb506e02-ff20-453e-83fb-0b7b5de17abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option frequency in FA:\n",
      "GPT4o_FA\n",
      "B    37.0\n",
      "C    28.0\n",
      "D    18.0\n",
      "A    17.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Option frequency in FA:\")\n",
    "print(df[\"GPT4o_FA\"].value_counts(normalize=True).round(2) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b54245ca-0647-4a68-9413-54987b02b1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Exported 30 disagreement cases to GPT4o_Disagreements.csv\n",
      "‚úÖ Saved domain-wise disagreement counts to Disagreement_By_Domain.csv\n",
      "\n",
      "üìä Top domains with most disagreement:\n",
      "                     Domain  Disagreement_Count\n",
      "0             Law & Justice                   5\n",
      "1     Politics & Leadership                   4\n",
      "2   Religion & Spirituality                   4\n",
      "3      Science & Technology                   3\n",
      "4        Journalism & Media                   3\n",
      "5                 Education                   2\n",
      "6     Hospitality & Service                   2\n",
      "7  Activism & Social Change                   2\n",
      "8    Caregiving & Parenting                   2\n",
      "9                Healthcare                   1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your aligned results\n",
    "df = pd.read_csv(\"GPT4o_Merged_Multilingual.csv\")\n",
    "\n",
    "# Identify disagreement rows (not all 3 agree)\n",
    "df[\"Disagreement\"] = (df[\"GPT4o_EN\"] != df[\"GPT4o_FA\"]) | \\\n",
    "                     (df[\"GPT4o_EN\"] != df[\"GPT4o_IT\"]) | \\\n",
    "                     (df[\"GPT4o_FA\"] != df[\"GPT4o_IT\"])\n",
    "\n",
    "# Export only the rows with disagreement\n",
    "df_disagreement = df[df[\"Disagreement\"] == True]\n",
    "df_disagreement.to_csv(\"GPT4o_Disagreements.csv\", index=False)\n",
    "print(f\"‚úÖ Exported {len(df_disagreement)} disagreement cases to GPT4o_Disagreements.csv\")\n",
    "\n",
    "# Count disagreement cases per domain\n",
    "disagreement_by_domain = df_disagreement[\"Domain_EN\"].value_counts().reset_index()\n",
    "disagreement_by_domain.columns = [\"Domain\", \"Disagreement_Count\"]\n",
    "disagreement_by_domain.to_csv(\"Disagreement_By_Domain.csv\", index=False)\n",
    "print(\"‚úÖ Saved domain-wise disagreement counts to Disagreement_By_Domain.csv\")\n",
    "\n",
    "# (Optional) Show most frequent disagreement domains in console\n",
    "print(\"\\nüìä Top domains with most disagreement:\")\n",
    "print(disagreement_by_domain.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cf41448-de1f-4cf7-bac9-22f2d9af1a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Full Agreement Rate:\n",
      "30/60 prompts (50.00%)\n",
      "\n",
      "üß© Disagreement Types:\n",
      "                   count\n",
      "Disagreement_Type       \n",
      "All same              30\n",
      "FA diverged           11\n",
      "EN diverged            7\n",
      "All different          7\n",
      "IT diverged            5 \n",
      "\n",
      "üó≥Ô∏è Option Frequency in Persian (GPT4o_FA):\n",
      "          proportion\n",
      "GPT4o_FA            \n",
      "B           0.366667\n",
      "C           0.283333\n",
      "D           0.183333\n",
      "A           0.166667 \n",
      "\n",
      "üåç Domain-wise Disagreements:\n",
      "                          count\n",
      "Domain_EN                      \n",
      "Law & Justice                 5\n",
      "Politics & Leadership         4\n",
      "Religion & Spirituality       4\n",
      "Science & Technology          3\n",
      "Journalism & Media            3\n",
      "Education                     2\n",
      "Hospitality & Service         2\n",
      "Activism & Social Change      2\n",
      "Caregiving & Parenting        2\n",
      "Healthcare                    1\n",
      "Arts & Culture                1\n",
      "Business & Economics          1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Load merged results file\n",
    "df = pd.read_csv(\"GPT4o_Merged_Multilingual.csv\")\n",
    "\n",
    "# Check full agreement\n",
    "df[\"Full_Agreement\"] = (df[\"GPT4o_EN\"] == df[\"GPT4o_FA\"]) & (df[\"GPT4o_EN\"] == df[\"GPT4o_IT\"])\n",
    "\n",
    "# Classify type of disagreement\n",
    "def classify_disagreement(row):\n",
    "    choices = {row[\"GPT4o_EN\"], row[\"GPT4o_FA\"], row[\"GPT4o_IT\"]}\n",
    "    if len(choices) == 1:\n",
    "        return \"All same\"\n",
    "    elif len(choices) == 3:\n",
    "        return \"All different\"\n",
    "    elif row[\"GPT4o_EN\"] != row[\"GPT4o_FA\"] and row[\"GPT4o_EN\"] == row[\"GPT4o_IT\"]:\n",
    "        return \"FA diverged\"\n",
    "    elif row[\"GPT4o_EN\"] != row[\"GPT4o_IT\"] and row[\"GPT4o_EN\"] == row[\"GPT4o_FA\"]:\n",
    "        return \"IT diverged\"\n",
    "    elif row[\"GPT4o_EN\"] != row[\"GPT4o_FA\"] and row[\"GPT4o_FA\"] == row[\"GPT4o_IT\"]:\n",
    "        return \"EN diverged\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "df[\"Disagreement_Type\"] = df.apply(classify_disagreement, axis=1)\n",
    "\n",
    "# Count full agreement\n",
    "agreement_count = df[\"Full_Agreement\"].sum()\n",
    "total = len(df)\n",
    "agreement_pct = agreement_count / total * 100\n",
    "\n",
    "# Disagreement breakdown\n",
    "disagreement_summary = df[\"Disagreement_Type\"].value_counts().to_frame(\"count\")\n",
    "\n",
    "# Frequency of choices in Persian\n",
    "fa_freq = df[\"GPT4o_FA\"].value_counts(normalize=True).rename(\"proportion\").to_frame()\n",
    "\n",
    "# Domain-wise disagreement\n",
    "domain_disagreements = df[df[\"Disagreement_Type\"] != \"All same\"][\"Domain_EN\"].value_counts().to_frame(\"count\")\n",
    "\n",
    "# Display everything\n",
    "print(\"üîé Full Agreement Rate:\")\n",
    "print(f\"{agreement_count}/{total} prompts ({agreement_pct:.2f}%)\\n\")\n",
    "\n",
    "print(\"üß© Disagreement Types:\")\n",
    "print(disagreement_summary, \"\\n\")\n",
    "\n",
    "print(\"üó≥Ô∏è Option Frequency in Persian (GPT4o_FA):\")\n",
    "print(fa_freq, \"\\n\")\n",
    "\n",
    "print(\"üåç Domain-wise Disagreements:\")\n",
    "print(domain_disagreements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bab0cd13-1633-4854-a8c7-d11c213f143f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Agreement Confidence Interval for GPT4o:\n",
      "Mean Agreement: 50.02%\n",
      "95% CI: [38.33%, 61.71%]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def bootstrap_agreement_confidence_interval(filepath, model_prefix=\"GPT4o\", num_bootstrap=1000, confidence=0.95):\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    # Compute agreement column\n",
    "    df[\"Full_Agreement\"] = (\n",
    "        (df[f\"{model_prefix}_EN\"] == df[f\"{model_prefix}_FA\"]) &\n",
    "        (df[f\"{model_prefix}_EN\"] == df[f\"{model_prefix}_IT\"])\n",
    "    )\n",
    "\n",
    "    # Store bootstrapped agreement rates\n",
    "    bootstrapped_agreements = []\n",
    "\n",
    "    for _ in range(num_bootstrap):\n",
    "        sample = df.sample(frac=1.0, replace=True)\n",
    "        agreement_pct = sample[\"Full_Agreement\"].mean() * 100\n",
    "        bootstrapped_agreements.append(agreement_pct)\n",
    "\n",
    "    # Compute confidence interval\n",
    "    lower = np.percentile(bootstrapped_agreements, (1 - confidence) / 2 * 100)\n",
    "    upper = np.percentile(bootstrapped_agreements, (1 + confidence) / 2 * 100)\n",
    "    mean = np.mean(bootstrapped_agreements)\n",
    "\n",
    "    print(f\"üìà Agreement Confidence Interval for {model_prefix}:\")\n",
    "    print(f\"Mean Agreement: {mean:.2f}%\")\n",
    "    print(f\"{int(confidence * 100)}% CI: [{lower:.2f}%, {upper:.2f}%]\")\n",
    "\n",
    "    return mean, lower, upper\n",
    "\n",
    "# Run the function\n",
    "if __name__ == \"__main__\":\n",
    "    bootstrap_agreement_confidence_interval(\"GPT4o_Merged_Multilingual.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2979d508-9ca7-4e7e-b6e8-c98ac0bb1cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Disagreement Confidence Interval for GPT4o:\n",
      "Mean Disagreement: 49.95%\n",
      "95% CI: [38.33%, 63.33%]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def bootstrap_disagreement_confidence_interval(filepath, model_prefix=\"GPT4o\", num_bootstrap=1000, confidence=0.95):\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    # Compute disagreement column (negation of full agreement)\n",
    "    df[\"Disagreement\"] = ~(\n",
    "        (df[f\"{model_prefix}_EN\"] == df[f\"{model_prefix}_FA\"]) &\n",
    "        (df[f\"{model_prefix}_EN\"] == df[f\"{model_prefix}_IT\"])\n",
    "    )\n",
    "\n",
    "    # Store bootstrapped disagreement rates\n",
    "    bootstrapped_disagreements = []\n",
    "\n",
    "    for _ in range(num_bootstrap):\n",
    "        sample = df.sample(frac=1.0, replace=True)\n",
    "        disagreement_pct = sample[\"Disagreement\"].mean() * 100\n",
    "        bootstrapped_disagreements.append(disagreement_pct)\n",
    "\n",
    "    # Compute confidence interval\n",
    "    lower = np.percentile(bootstrapped_disagreements, (1 - confidence) / 2 * 100)\n",
    "    upper = np.percentile(bootstrapped_disagreements, (1 + confidence) / 2 * 100)\n",
    "    mean = np.mean(bootstrapped_disagreements)\n",
    "\n",
    "    print(f\"üìâ Disagreement Confidence Interval for {model_prefix}:\")\n",
    "    print(f\"Mean Disagreement: {mean:.2f}%\")\n",
    "    print(f\"{int(confidence * 100)}% CI: [{lower:.2f}%, {upper:.2f}%]\")\n",
    "\n",
    "    return mean, lower, upper\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    bootstrap_disagreement_confidence_interval(\"GPT4o_Merged_Multilingual.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c184d386-6c53-493e-b765-d5a33506dcb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
